"""
Vai trÃ² trong NDCG

DÃ¹ng Ä‘á»ƒ xÃ¡c Ä‘á»‹nh context nÃ o lÃ  liÃªn quan

So vá»›i contexts_answer Ä‘á»ƒ gÃ¡n relevance

2. contexts_answer lÃ  gÃ¬?
Äá»‹nh nghÄ©a Ä‘Ãºng

contexts_answer = danh sÃ¡ch top-k Ä‘oáº¡n vÄƒn (chunks) Ä‘Æ°á»£c retrieve

Output cá»§a retriever (BM25 / FAISS / vector DB)

ÄÃ£ Ä‘Æ°á»£c xáº¿p háº¡ng

Thá»© tá»± ráº¥t quan trá»ng

VÃ­ dá»¥:

contexts_answer = [
   chunk_1,  # rank 1
   chunk_2,  # rank 2
   chunk_3,  # rank 3
]

3. Má»‘i quan há»‡ giá»¯a hai cá»™t (cá»‘t lÃµi NDCG)
ThÃ nh pháº§n	Vai trÃ²
ground_truth	â€œCÃ¢u tráº£ lá»i Ä‘Ãºng lÃ  gÃ¬?â€
contexts_answer[i]	â€œÄoáº¡n nÃ y cÃ³ giÃºp tráº£ lá»i khÃ´ng?â€
relevance	má»©c Ä‘á»™ giÃºp tráº£ lá»i
NDCG	context Ä‘Ãºng cÃ³ náº±m trÃªn cao khÃ´ng
4. Minh há»a trá»±c quan
VÃ­ dá»¥
ground_truth:
"73,75 triá»‡u Ä‘á»“ng/lÆ°á»£ng (mua vÃ o)"

contexts_answer:
1. "79,5 triá»‡u Ä‘á»“ng/lÆ°á»£ng (mua vÃ o)" âŒ
2. "73,75 triá»‡u Ä‘á»“ng/lÆ°á»£ng (mua vÃ o)" âœ…
3. "GiÃ¡ vÃ ng tháº¿ giá»›i tÄƒng..." âŒ

relevance (graded)
[0, 3, 0]

NDCG@3

Context Ä‘Ãºng náº±m á»Ÿ vá»‹ trÃ­ 2

NDCG < 1 (bá»‹ pháº¡t vÃ¬ khÃ´ng Ä‘á»©ng top-1)

ğŸ‘‰ ÄÃºng Ã½ nghÄ©a NDCG

5. Nhá»¯ng hiá»ƒu nháº§m hay gáº·p (nÃªn trÃ¡nh)
âŒ DÃ¹ng contexts_ground_truth Ä‘á»ƒ tÃ­nh NDCG

â†’ sai, Ä‘Ã³ chá»‰ lÃ  nguá»“n file

âŒ So answer vá»›i context

â†’ Ä‘Ã³ lÃ  QA accuracy, khÃ´ng pháº£i retrieval

âŒ So context chá»©a toÃ n bá»™ bÃ i bÃ¡o

â†’ khÃ´ng thá»±c táº¿ vá»›i chunking

6. Rule vÃ ng (nhá»› ká»¹)

ground_truth = Ä‘Ã¡p Ã¡n
contexts_answer = tÃ i liá»‡u Ä‘á»ƒ tÃ¬m Ä‘Ã¡p Ã¡n
NDCG = tÃ i liá»‡u Ä‘Ãºng cÃ³ Ä‘Æ°á»£c xáº¿p lÃªn trÃªn khÃ´ng

7. TÃ³m táº¯t 1 dÃ²ng

NDCG tráº£ lá»i cÃ¢u há»i: â€œRetriever cÃ³ Ä‘Æ°a tÃ i liá»‡u Ä‘Ãºng lÃªn Ä‘áº§u danh sÃ¡ch khÃ´ng?â€
"""

import math
import ast
import pandas as pd
import re
import os


# =====================
# TOKENIZE ÄÆ N GIáº¢N
# =====================
def tokenize(text: str):
    text = text.lower()
    text = re.sub(r"[^\w\s]", " ", text)
    return set(text.split())


# =====================
# RELEVANCE (GRADED)
# =====================
def relevance_graded(ground_truth: str, context: str) -> int:
    gt_tokens = tokenize(ground_truth)
    ctx_tokens = tokenize(context)

    if not gt_tokens:
        return 0

    overlap = len(gt_tokens & ctx_tokens) / len(gt_tokens)

    if overlap >= 0.6:
        return 3
    elif overlap >= 0.3:
        return 2
    elif overlap >= 0.1:
        return 1
    return 0


# =====================
# DCG / NDCG
# =====================
def dcg_at_k(rels, k):
    return sum(rel / math.log2(i + 2) for i, rel in enumerate(rels[:k]))


def ndcg_at_k(rels, k):
    dcg = dcg_at_k(rels, k)
    ideal = sorted(rels, reverse=True)
    idcg = dcg_at_k(ideal, k)
    return dcg / idcg if idcg > 0 else 0.0


# =====================
# TÃNH NDCG CHO 1 DÃ’NG
# =====================
def calc_ndcg_row(row, k=5):
    ground_truth = str(row["ground_truth"]).strip()

    try:
        contexts = ast.literal_eval(row["contexts_answer"])
        if not isinstance(contexts, list):
            return 0.0
    except Exception:
        return 0.0

    relevances = [relevance_graded(ground_truth, ctx) for ctx in contexts]

    if sum(relevances) == 0:
        return 0.0

    return ndcg_at_k(relevances, k)


# =====================
# CHáº Y TRÃŠN EXCEL
# =====================
def ndcg_excel(path, k=5, out=None):
    df = pd.read_excel(path)

    df[f"NDCG@{k}"] = df.apply(lambda r: calc_ndcg_row(r, k), axis=1)

    if not out:
        dir_name = os.path.dirname(path)
        base_name = os.path.basename(path)
        out = os.path.join(
            dir_name, f"END_{base_name.replace('.xlsx', f'_ndcg{k}.xlsx')}"
        )

    df.to_excel(out, index=False)

    print("âœ… Done:", out)
    print("ğŸ“Š Mean NDCG:", df[f"NDCG@{k}"].mean())

    return out
