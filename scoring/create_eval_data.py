"""
Script táº¡o file evaluation tá»« chatbot.

BÆ°á»›c 1: Cháº¡y script nÃ y Ä‘á»ƒ chatbot tráº£ lá»i cÃ¡c cÃ¢u há»i
BÆ°á»›c 2: Má»Ÿ file Excel, Ä‘iá»n cá»™t "ground_truth" thá»§ cÃ´ng
BÆ°á»›c 3: Cháº¡y scoring/main.py Ä‘á»ƒ cháº¥m Ä‘iá»ƒm
"""

import os
import sys
from pathlib import Path

# ThÃªm parent folder vÃ o path
sys.path.insert(0, str(Path(__file__).parent.parent))

import pandas as pd
from chatbot.main import ChatbotRunner


def create_evaluation_file(questions: list, output_file: str = "eval_data.xlsx"):
    """
    Cháº¡y chatbot vá»›i danh sÃ¡ch cÃ¢u há»i vÃ  lÆ°u káº¿t quáº£ ra Excel.
    
    Args:
        questions: Danh sÃ¡ch cÃ¢u há»i cáº§n test
        output_file: TÃªn file Excel output
    """
    
    # Khá»Ÿi táº¡o chatbot
    print("ğŸš€ Äang khá»Ÿi táº¡o chatbot...")
    chatbot = ChatbotRunner(
        path_vector_store="./chroma_economy_db",
        llm_provider="groq"
    )
    
    results = []
    
    for i, question in enumerate(questions, 1):
        print(f"\n{'='*60}")
        print(f"ğŸ“ [{i}/{len(questions)}] CÃ¢u há»i: {question}")
        print(f"{'='*60}")
        
        # Chuáº©n bá»‹ input
        input_state = {
            "question": question,
            "generation": "",
            "documents": [],
            "prompt": "Báº¡n lÃ  má»™t chuyÃªn gia tÆ° váº¥n kinh táº¿ Viá»‡t Nam."
        }
        
        # Cháº¡y workflow
        try:
            output_state = chatbot.compiled_workflow.invoke(input_state)
            
            answer = output_state.get("generation", "")
            documents = output_state.get("documents", [])
            
            # Láº¥y contexts tá»« documents
            contexts = [doc.page_content for doc in documents]
            
            results.append({
                "question": question,
                "ground_truth": "",  # <-- ÄIá»€N THá»¦ CÃ”NG SAU
                "contexts_ground_truth": "",  # <-- TÃ™Y CHá»ŒN
                "answer": answer,
                "contexts_answer": str(contexts),
                "metadata": str([doc.metadata for doc in documents]) if documents else ""
            })
            
            print(f"âœ… ÄÃ£ xá»­ lÃ½ thÃ nh cÃ´ng")
            
        except Exception as e:
            print(f"âŒ Lá»—i: {e}")
            results.append({
                "question": question,
                "ground_truth": "",
                "contexts_ground_truth": "",
                "answer": f"ERROR: {e}",
                "contexts_answer": "[]",
                "metadata": ""
            })
    
    # LÆ°u ra Excel
    df = pd.DataFrame(results)
    output_path = os.path.join(os.path.dirname(__file__), output_file)
    df.to_excel(output_path, index=False)
    
    print(f"\n{'='*60}")
    print(f"âœ… ÄÃ£ lÆ°u {len(results)} káº¿t quáº£ vÃ o: {output_path}")
    print(f"ğŸ“ BÆ¯á»šC TIáº¾P THEO: Má»Ÿ file Excel vÃ  Ä‘iá»n cá»™t 'ground_truth' thá»§ cÃ´ng")
    print(f"   Sau Ä‘Ã³ cháº¡y: python scoring/main.py")
    print(f"{'='*60}")
    
    return output_path


# ============ CÃ‚U Há»I TEST ============
# ThÃªm/sá»­a cÃ¢u há»i táº¡i Ä‘Ã¢y
TEST_QUESTIONS = [
    "10 sá»± kiá»‡n kinh táº¿ xÃ£ há»™i ná»•i báº­t nÄƒm 2023 lÃ  gÃ¬?",
    "Dá»± Ã¡n Ä‘Æ°á»ng VÃ nh Ä‘ai 4 TP.HCM cÃ³ tá»•ng má»©c Ä‘áº§u tÆ° bao nhiÃªu?",
    "ChÆ°Æ¡ng trÃ¬nh nhÃ  á»Ÿ xÃ£ há»™i TP.HCM cÃ³ bao nhiÃªu dá»± Ã¡n?",
    "TÃ¬nh hÃ¬nh thá»‹ trÆ°á»ng báº¥t Ä‘á»™ng sáº£n nÄƒm 2023 nhÆ° tháº¿ nÃ o?",
    "GDP Viá»‡t Nam nÄƒm 2023 tÄƒng trÆ°á»Ÿng bao nhiÃªu?",
]


if __name__ == "__main__":
    create_evaluation_file(TEST_QUESTIONS, "eval_data.xlsx")
