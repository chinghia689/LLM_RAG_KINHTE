import os
import hashlib
import shutil
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_chroma import Chroma


class ChromaDBManager:
    """
    Class quáº£n lÃ½ Vector Database (Chroma) vÃ  xá»­ lÃ½ cáº¯t vÄƒn báº£n.
    """
    def __init__(self, embeddings_model=None, persist_dir='./chroma_economy_db'):
        # Nháº­n embedding model (lazy: náº¿u khÃ´ng truyá»n thÃ¬ tá»± láº¥y tá»« vn_embedder)
        if embeddings_model is None:
            from ingestion.model_embedding import vn_embedder
            embeddings_model = vn_embedder.get_model()
        self.embeddings = embeddings_model
        self.persist_dir = persist_dir
        self.vector_store = None

    def process_and_store(self, raw_documents, chunk_size=600, chunk_overlap=80, force_rebuild=False):
        """
        HÃ m thá»±c hiá»‡n cáº¯t vÄƒn báº£n vÃ  lÆ°u vÃ o Database.
        
        Args:
            raw_documents: Danh sÃ¡ch documents gá»‘c
            chunk_size: KÃ­ch thÆ°á»›c chunk
            chunk_overlap: Sá»‘ kÃ½ tá»± overlap
            force_rebuild: Náº¿u True, xÃ³a DB cÅ© vÃ  táº¡o láº¡i tá»« Ä‘áº§u
        """
        # 2. Xá»­ lÃ½ VectorDB (Chroma)
        if os.path.exists(self.persist_dir) and not force_rebuild:
            print(f"ğŸ“‚ ÄÃ£ tÃ¬m tháº¥y DB cÅ© táº¡i '{self.persist_dir}'. Äang load...")
            # Load DB cÅ© â€” KHÃ”NG thÃªm láº¡i data Ä‘á»ƒ trÃ¡nh trÃ¹ng láº·p
            self.vector_store = Chroma(
                persist_directory=self.persist_dir,
                embedding_function=self.embeddings
            )
            print(f"âœ… ÄÃ£ load DB vá»›i {self.vector_store._collection.count()} vectors.")
            return
        
        # Náº¿u force_rebuild, xÃ³a DB cÅ©
        if force_rebuild and os.path.exists(self.persist_dir):
            shutil.rmtree(self.persist_dir)
            print(f"ğŸ—‘ï¸ ÄÃ£ xÃ³a DB cÅ© táº¡i '{self.persist_dir}'.")

        print(f"âœ‚ï¸ Äang cáº¯t {len(raw_documents)} vÄƒn báº£n gá»‘c...")
        
        # 1. Cáº¥u hÃ¬nh Splitter
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=chunk_size,
            chunk_overlap=chunk_overlap,
            separators=['\n\n', '\n']
        )
        
        # Cáº¯t thÃ nh cÃ¡c chunk nhá»
        doc_splits = text_splitter.split_documents(raw_documents)
        print(f"âœ… ÄÃ£ cáº¯t thÃ nh {len(doc_splits)} chunks nhá».")

        # === DEDUPLICATION: Loáº¡i bá» chunks trÃ¹ng ná»™i dung ===
        seen_hashes = set()
        unique_splits = []
        for doc in doc_splits:
            content_hash = hashlib.md5(
                doc.page_content.strip().encode("utf-8")
            ).hexdigest()
            if content_hash not in seen_hashes:
                seen_hashes.add(content_hash)
                unique_splits.append(doc)
        
        removed = len(doc_splits) - len(unique_splits)
        print(f"ğŸ”„ Dedup: {len(doc_splits)} â†’ {len(unique_splits)} chunks (loáº¡i {removed} trÃ¹ng láº·p)")
        doc_splits = unique_splits

        print(f"ğŸ†• Äang táº¡o DB má»›i táº¡i '{self.persist_dir}'...")
        # Táº¡o má»›i hoÃ n toÃ n
        self.vector_store = Chroma.from_documents(
            documents=doc_splits,
            embedding=self.embeddings,
            persist_directory=self.persist_dir
        )
        print("âœ… ÄÃ£ táº¡o vÃ  lÆ°u DB má»›i thÃ nh cÃ´ng!")

    def get_retriever(self, k=40):
        """HÃ m láº¥y retriever ra Ä‘á»ƒ tÃ¬m kiáº¿m"""
        if not self.vector_store:
            if os.path.exists(self.persist_dir):
                self.vector_store = Chroma(
                    persist_directory=self.persist_dir,
                    embedding_function=self.embeddings
                )
            else:
                raise ValueError("âŒ Database chÆ°a Ä‘Æ°á»£c táº¡o. HÃ£y cháº¡y process_and_store() trÆ°á»›c!")
                
        # Tráº£ vá» retriever
        return self.vector_store.as_retriever(search_kwargs={'k': k})
